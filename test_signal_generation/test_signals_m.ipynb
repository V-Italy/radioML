{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy import pi\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle as cPickle\n",
    "# #Sine wave\n",
    "\n",
    "# N = 128\n",
    "\n",
    "# def get_sine_wave():\n",
    "#     x_sin = np.array([0.0 for i in range(N)])\n",
    "#     # print(x_sin)\n",
    "#     for i in range(N):\n",
    "#         # print(\"h\")\n",
    "#         x_sin[i] = np.sin(2.0*pi*i/16.0)\n",
    "\n",
    "#     plt.plot(x_sin)\n",
    "#     plt.title('Sine wave')\n",
    "#     plt.show()\n",
    "\n",
    "#     y_sin = np.fft.fftshift(np.fft.fft(x_sin[:16], 16))\n",
    "#     plt.plot(abs(y_sin))\n",
    "#     plt.title('FFT sine wave')\n",
    "#     plt.show()\n",
    "\n",
    "#     return x_sin\n",
    "\n",
    "# def get_bpsk_carrier():\n",
    "#     x = np.fromfile('gnuradio_dumps/bpsk_carrier', dtype = 'float32')\n",
    "#     x_bpsk_carrier = x[9000:9000+N]\n",
    "#     plt.plot(x_bpsk_carrier)\n",
    "#     plt.title('BPSK carrier')\n",
    "#     plt.show()\n",
    "    \n",
    "#     y_bpsk_carrier =  np.fft.fft(x_bpsk_carrier, N)\n",
    "#     plt.plot(abs(y_bpsk_carrier))\n",
    "#     plt.title('FFT BPSK carrier')\n",
    "#     plt.show()\n",
    "    \n",
    "#     return x_bpsk_carrier\n",
    "\n",
    "\n",
    "# def get_qpsk_carrier():\n",
    "#     x = np.fromfile('gnuradio_dumps/qpsk_carrier', dtype = 'float32')\n",
    "#     x_qpsk_carrier = x[12000:12000+N]\n",
    "#     plt.plot(x_qpsk_carrier)\n",
    "#     plt.title('QPSK carrier')\n",
    "#     plt.show()\n",
    "\n",
    "\n",
    "#     # y_qpsk_carrier =  np.fft.fft(x_qpsk_carrier, N)\n",
    "#     # plt.plot(abs(y_qpsk_carrier))\n",
    "#     # plt.title('FFT QPSK carrier')\n",
    "#     # plt.show()\n",
    "    \n",
    "#     return x_qpsk_carrier\n",
    "\n",
    "# def get_bpsk():\n",
    "#     x = np.fromfile('gnuradio_dumps/bpsk', dtype = 'complex64')\n",
    "#     x_bpsk = x[9000:9000+N]\n",
    "#     plt.plot(x_bpsk.real)\n",
    "#     plt.plot(x_bpsk.imag)\n",
    "#     plt.title('BPSK')\n",
    "#     plt.show()\n",
    "\n",
    "\n",
    "\n",
    "#     # y_bpsk =  np.fft.fft(x_bpsk, N)\n",
    "#     # plt.plot(abs(y_bpsk))\n",
    "#     # plt.title('FFT BPSK')\n",
    "#     # plt.show()\n",
    "    \n",
    "#     return x_bpsk\n",
    "\n",
    "# def get_qpsk():\n",
    "#     x = np.fromfile('gnuradio_dumps/qpsk', dtype = 'complex64')\n",
    "#     x_qpsk = x[11000:11000+N]\n",
    "#     plt.plot(x_qpsk.real)\n",
    "#     plt.plot(x_qpsk.imag)\n",
    "#     plt.title('QPSK')\n",
    "#     plt.show()\n",
    "\n",
    "\n",
    "\n",
    "#     # y_qpsk =  np.fft.fft(x_bpsk, N)\n",
    "#     # plt.plot(abs(y_bqsk))\n",
    "#     # plt.title('FFT QPSK')\n",
    "#     # plt.show()\n",
    "    \n",
    "#     return x_qpsk\n",
    "\n",
    "def load_dataset(location=\"../../datasets/radioml.dat\"):\n",
    "    f = open(location, \"rb\")\n",
    "    ds = cPickle.load(f, encoding = 'latin-1')\n",
    "    return ds\n",
    "\n",
    "\n",
    "# def get_from_dataset(dataset, key):\n",
    "#     \"\"\"Returns complex version of dataset[key][500]\"\"\"\n",
    "#     xr = dataset[key][500][0]\n",
    "#     xi = dataset[key][500][1]\n",
    "#     plt.plot(xr)\n",
    "#     plt.plot(xi)\n",
    "#     plt.title(key)\n",
    "#     plt.show()\n",
    "#     return xr+1j*xi\n",
    "\n",
    "# x_sin = get_sine_wave()\n",
    "# x_bpsk_carrier = get_bpsk_carrier()\n",
    "# x_qpsk_carrier = get_qpsk_carrier()\n",
    "# x_bpsk = get_bpsk()\n",
    "# x_qpsk = get_qpsk()\n",
    "\n",
    "# ds = load_dataset(location=\"../modulation_recognition/RML2016.10a_dict.dat\")\n",
    "# x_amssb = get_from_dataset(dataset=ds, key=('AM-SSB', 0))\n",
    "# x_amdsb = get_from_dataset(dataset=ds, key= ('AM-DSB', 0))\n",
    "# x_gfsk = get_from_dataset(dataset=ds, key=('GFSK', 0))\n",
    "# x_bpsk_dataset = get_from_dataset(dataset=ds, key = ('BPSK',18))\n",
    "# x_qpsk_dataset = get_from_dataset(dataset=ds, key = ('QPSK',0))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "nfft = 16\n",
    "cyclo_averaging = 8\n",
    "offsets = [0,1,2,3,4,5,6,7]\n",
    "zero_threshold = 1e-3\n",
    "\n",
    "def round_to_zero(data, zero_threshold):\n",
    "    '''Set entries with absolute values below threshold to zero'''\n",
    "    data_rounded = data\n",
    "    for k,s in enumerate(data):\n",
    "        if abs(s) < zero_threshold:\n",
    "            data_rounded[k] = 0\n",
    "    return data_rounded\n",
    "    \n",
    "def compute_cyclo_fft(data, nfft):  \n",
    "    '''\n",
    "    Split data into blocks of size nfft and compute fft for each block       \n",
    "    Input:data: length N (say), \n",
    "          nfft: size of fft\n",
    "    Output: nfft x N/nfft size matrix where jth column contains fft of jth block\n",
    "    '''\n",
    "\n",
    "    data_reshape = np.reshape(data, (-1, nfft))    \n",
    "    y =  np.fft.fftshift(np.fft.fft(data_reshape, axis=1), axes=1)  \n",
    "#     plt.plot(data_reshape[0,:].real)\n",
    "#     plt.title('Sample Data ' + str(nfft) + ' points')\n",
    "#     plt.show()\n",
    "    return y.T\n",
    "\n",
    "\n",
    "def compute_correlation(x,y):\n",
    "    '''\n",
    "    Input: x and y are arrays to be correlated\n",
    "    Output: inner product of x and y divided by length of x'''\n",
    "    x = np.reshape(x, [-1,])\n",
    "    y = np.reshape(y, [-1,])\n",
    "    lenx = x.shape[0]\n",
    "    corr = 0\n",
    "    for i in range(lenx):\n",
    "        corr += x[i]*np.conj(y[i])        \n",
    "    corr /= lenx\n",
    "    return corr\n",
    "\n",
    "def compute_coefficients(cyc_fft, alphas):\n",
    "    '''\n",
    "    Input:nfft X cyclo_averaging size matrix where jth column is fft of a sample\n",
    "    Output:specs: nfft X num_offsets size matrix where jth column contains spectral coefficients corresponding to its alpha(offset)\n",
    "           scs: nfft X num_offsets size matrix where jth column contains scaled spectral coefficients corresponding to its alpha(offset)\n",
    "    The spectral coefficients close to 0 are set to exactly zero before scaling to obtain scs\n",
    "    '''       \n",
    "\n",
    "    specs = np.zeros((nfft,len(alphas)), dtype=np.complex)\n",
    "    scs = np.zeros((nfft,len(alphas)),dtype=np.complex)\n",
    "    for alpha in alphas:\n",
    "        z = np.array(np.zeros(cyc_fft.shape), dtype=np.complex)\n",
    "        denom_right = np.zeros(cyc_fft.shape, dtype=np.complex)\n",
    "        denom_left = np.zeros(cyc_fft.shape,dtype=np.complex)        \n",
    "        for i in range(cyc_fft.shape[1]):\n",
    "            x = cyc_fft[:,i]\n",
    "            x_right = np.roll(x, alpha)\n",
    "            x_left = np.roll(x, -alpha)\n",
    "            z[:,i] = (x_right*np.conj(x_left))/cyc_fft.shape[1]                        \n",
    "            \n",
    "            denom_right[:,i] =(x_right*np.conj(x_right)/cyc_fft.shape[1])\n",
    "            denom_left[:,i] = (x_left*np.conj(x_left)/cyc_fft.shape[1])            \n",
    "            spec = np.mean(z,axis=1)   \n",
    "            denom = np.sqrt(np.abs(np.mean(denom_right, axis=1))*np.abs(np.mean(denom_left,axis=1)))\n",
    "           \n",
    "            specs[:,alpha] = spec\n",
    "            spec = round_to_zero(spec, zero_threshold)           \n",
    "            sc = spec/denom\n",
    "            scs[:,alpha] = sc \n",
    "            \n",
    "    return specs, scs\n",
    "\n",
    "def cyclo_stationary(data):\n",
    "    cyc_fft = compute_cyclo_fft(data, nfft)  \n",
    "    specs, scs = compute_coefficients(cyc_fft,alphas = offsets)\n",
    "    return specs, scs    \n",
    "\n",
    "def convert_to_1d(data_2d):\n",
    "    '''Stacks columns below each other'''\n",
    "    M,N= data_2d.shape\n",
    "    data_1d = np.zeros((M*N,),dtype=np.complex)\n",
    "    for i in range(N):\n",
    "        data_1d[i*M:(i+1)*M] = data_2d[:,i]        \n",
    "    return data_1d\n",
    "\n",
    "# def visualize_2d(data_list, key_list, title, alphas, group='key'):  \n",
    "#     '''\n",
    "#     If group is 'key' for each alpha plot specs for all keys in one plot\n",
    "#     If group is 'alpha' for each key plot specs for all alphas in one plot\n",
    "#     '''\n",
    "#     if group == 'key':\n",
    "#         for alpha in alphas:\n",
    "#             for k,data in enumerate(data_list):\n",
    "#                 key = key_list[k]\n",
    "#                 plt.plot(abs(data[:,alpha]), 'o--', label = key)            \n",
    "#             plt.title(title+', Alpha:' + str(alpha))        \n",
    "#             plt.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)\n",
    "#             plt.xlabel('f/fs')\n",
    "#             plt.ylabel('alpha/fs')\n",
    "#             plt.show() \n",
    "#     elif group == 'alpha':\n",
    "#         for k,key in enumerate(key_list):\n",
    "#             data = data_list[k]\n",
    "#             for alpha in alphas:\n",
    "#                 plt.plot(abs(data[:,alpha]), 'o--', label='Alpha:' +str(alpha))\n",
    "#             plt.title(title + ', Key: ' + str(key))\n",
    "#             plt.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)\n",
    "#             plt.xlabel('f/fs')\n",
    "#             plt.ylabel('alpha/fs')\n",
    "#             plt.show() \n",
    "\n",
    "# def visualize_1d(data_list, key_list, title):\n",
    "#     for k,data in enumerate(data_list):\n",
    "#         key = key_list[k]        \n",
    "#         plt.plot(abs(data), 'x--', label = str(key))\n",
    "#     plt.title(title)    \n",
    "#     plt.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)\n",
    "#     plt.show()\n",
    "\n",
    "\n",
    "# #Dataset QPSk\n",
    "# specs_2d_qpsk_real,scs_2d_qpsk_real = cyclo_stationary(x_qpsk_dataset.real)\n",
    "# specs_1d_qpsk_real = convert_to_1d(specs_2d_qpsk_real)\n",
    "# specs_2d_qpsk_imag,scs_2d_qpsk_imag = cyclo_stationary(x_qpsk_dataset.imag)\n",
    "# specs_1d_qpsk_imag= convert_to_1d(specs_2d_qpsk_imag)\n",
    "# visualize_1d(data_list=[specs_1d_qpsk_real, specs_1d_qpsk_imag], key_list=[\"Real('QPSK',18)\", \"Imag('QPSK',18)\" ], title='Specs(Magnitude)')\n",
    "\n",
    "# #Dataset BPSK\n",
    "# specs_2d_bpsk_real,scs_2d_bpsk_real = cyclo_stationary(x_bpsk_dataset.real)\n",
    "# specs_1d_bpsk_real = convert_to_1d(specs_2d_bpsk_real)\n",
    "# specs_2d_bpsk_imag,scs_2d_bpsk_imag = cyclo_stationary(x_bpsk_dataset.imag)\n",
    "# specs_1d_bpsk_imag= convert_to_1d(specs_2d_bpsk_imag)\n",
    "# visualize_1d(data_list=[specs_1d_bpsk_real, specs_1d_bpsk_imag],  key_list=[\"Real('BPSK',18)\", \"Imag('BPSK',18)\" ],  title='Specs(Magnitude)')\n",
    "\n",
    "\n",
    "# #BPSK,QPSK at carrier\n",
    "# specs_2d_bpsk_carrier,scs_2d_bpsk_carrier = cyclo_stationary(x_bpsk_carrier)\n",
    "# specs_1d_bpsk_carrier = convert_to_1d(specs_2d_bpsk_carrier)\n",
    "# specs_2d_qpsk_carrier,scs_2d_qpsk_carrier = cyclo_stationary(x_qpsk_carrier)\n",
    "# specs_1d_qpsk_carrier = convert_to_1d(specs_2d_qpsk_carrier)\n",
    "# visualize_1d(data_list=[specs_1d_qpsk_carrier, specs_1d_bpsk_carrier], key_list=[\"QPSK carrier\", \"BPSK carrier\"], title = 'Specs(Magnitude)')\n",
    "# visualize_2d(data_list = [specs_2d_qpsk_carrier, specs_2d_bpsk_carrier], key_list=[\"QPSK carrier\", \"BPSK_carrier\"], title = 'Specs(Magnitude)', alphas = offsets, group = 'key')\n",
    "# visualize_2d(data_list = [specs_2d_qpsk_carrier, specs_2d_bpsk_carrier ],  key_list=[\"QPSK carrier\", \"BPSK carrier\"], title = 'Specs(Magnitude)', alphas = offsets, group = 'alpha')\n",
    "\n",
    "# #Sine wave\n",
    "# specs_2d_sin,scs_2d_sin = cyclo_stationary(x_sin.real)\n",
    "# specs_1d_sin = convert_to_1d(specs_2d_sin)\n",
    "# visualize_1d(data_list=[specs_1d_sin],  key_list=[\"Sin\" ],  title='Specs(Magnitude)')\n",
    "# visualize_2d(data_list = [specs_2d_sin], key_list=[\"Sin\"], title = 'Specs(Magnitude)', alphas = offsets, group = 'key')\n",
    "# visualize_2d(data_list = [specs_2d_sin], key_list=[\"Sin\"], title = 'Specs(Magnitude)', alphas = offsets, group = 'alpha')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Classification onwards from here </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ds = load_dataset(location=\"../../datasets/radioml.dat\")\n",
    "# bpsk_18 = ds[(\"BPSK\", 18)]\n",
    "# qpsk_18 = ds[(\"QPSK\", 18)]\n",
    "# classes = {\"bpsk\": 0, \"qpsk\": 1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "def wrapper_cyclo(data):\n",
    "    \"\"\"Presumes data is n datapoints.\"\"\"\n",
    "    n, _ = data.shape\n",
    "    specs = np.zeros((n, 128), dtype = 'complex')\n",
    "    for i in tqdm(range(n)):\n",
    "#     for i in range(n):\n",
    "        a, _ = cyclo_stationary(data[i, :])\n",
    "        specs[i, :] = convert_to_1d(a)\n",
    "#         print(specs[0])\n",
    "    return specs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# snr_vals = list(map(lambda a: a[1], list(filter(lambda a:a[0] == 'BPSK' and a[1] != 18, list(ds.keys()), ))))\n",
    "# snr_vals = [16,14, 12, 10, 8, 6]\n",
    "# bpsk = ds[(\"BPSK\", 18)]\n",
    "# qpsk = ds[(\"QPSK\", 18)]\n",
    "# for i in snr_vals:\n",
    "#     bpsk = np.vstack([ds[(\"BPSK\", i)], bpsk])\n",
    "#     qpsk = np.vstack([ds[(\"QPSK\", i)], qpsk])\n",
    "# bpsk = np.add(bpsk[:, 0, :], 1j*bpsk[:, 1, :])\n",
    "# qpsk = np.add(qpsk[:, 0, :], 1j*qpsk[:, 1, :])\n",
    "# bpsk_features = wrapper_cyclo(bpsk)\n",
    "# qpsk_features = wrapper_cyclo(qpsk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# def create_train_test(data1, data2, shuffle=False):\n",
    "#     training_set = 0.7\n",
    "#     n1, _ = data1.shape\n",
    "#     n2, _ = data2.shape\n",
    "#     num_train_1 = int(n1 * training_set)\n",
    "#     num_train_2 = int(n2 * training_set)\n",
    "\n",
    "#     if shuffle:\n",
    "#         np.random.shuffle(data1)\n",
    "#         np.random.shuffle(data2)\n",
    "\n",
    "#     train_q = data1[:num_train_1, ]\n",
    "#     train_b = data2[:num_train_2, ]\n",
    "#     test_q = data1[num_train_1:, ]\n",
    "#     test_b = data2[num_train_2:, ]\n",
    "\n",
    "#     train_x = np.vstack((train_q, train_b))\n",
    "#     train_y = np.vstack((np.zeros((num_train_1, 1)), np.ones((num_train_2, 1)))) # data1 - 0, data2 - 1\n",
    "\n",
    "#     test_x = np.vstack((test_q, test_b))\n",
    "#     test_y = np.vstack((np.zeros((n1 - num_train_1, 1)), np.ones((n2 - num_train_2, 1))))\n",
    "\n",
    "#     # Time to mix the data\n",
    "#     together = np.hstack((train_x, train_y))\n",
    "#     if shuffle:\n",
    "#         np.random.shuffle(together)\n",
    "        \n",
    "#     train_x, train_y = np.hsplit(together, [together.shape[1] - 1])\n",
    "\n",
    "#     together = np.hstack((test_x, test_y))\n",
    "    \n",
    "#     if shuffle:\n",
    "#         np.random.shuffle(together)\n",
    "    \n",
    "#     test_x, test_y = np.hsplit(together, [together.shape[1] - 1])\n",
    "#     return train_x, train_y, test_x, test_y\n",
    "# def percentage_success(actual, predicted):\n",
    "#     return 1 - (np.linalg.norm(actual - predicted)**2 / (predicted.shape[0]))\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "def gamut_classification(train_x, train_y, test_x, test_y):\n",
    "    train_y = train_y.reshape([-1,])\n",
    "    clf = SVC(C = 1.0, kernel='poly')\n",
    "    clf.fit(train_x, train_y )\n",
    "    predicted = clf.predict(test_x).reshape((-1, 1))\n",
    "    print(\"Polynomial Kernel, SVM \", percentage_success(test_y, predicted))\n",
    "    clf = SVC(C = 1.0, kernel='rbf')\n",
    "    clf.fit(train_x, train_y)\n",
    "    predicted = clf.predict(test_x).reshape((-1, 1))\n",
    "    print(\"RBF Kernel, SVM \", percentage_success(test_y, predicted))\n",
    "    clf = SVC(C = 1.0, kernel='linear')\n",
    "    clf.fit(train_x, train_y)\n",
    "    predicted = clf.predict(test_x).reshape((-1, 1))\n",
    "    print(\"Linear Kernel, SVM \", percentage_success(test_y, predicted))\n",
    "    clf = RandomForestClassifier(max_depth=2, n_estimators=100)\n",
    "    clf.fit(train_x, train_y)\n",
    "    predicted = clf.predict(test_x).reshape((-1, 1))\n",
    "    print(\"Random Forests \", percentage_success(test_y, predicted))\n",
    "    clf = AdaBoostClassifier(n_estimators=100)\n",
    "    clf.fit(train_x, train_y)\n",
    "    predicted = clf.predict(test_x).reshape((-1, 1))\n",
    "    print(\"AdaBoost \", percentage_success(test_y, predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# train_x, train_y, test_x, test_y = create_train_test(bpsk_features, qpsk_features)\n",
    "\n",
    "# train_x_real_imag = np.hstack([train_x.real, train_x.imag])\n",
    "# test_x_real_imag = np.hstack([test_x.real, test_x.imag])\n",
    "\n",
    "# train_x_mag_phase = np.hstack([np.abs(train_x), np.angle(train_x)])\n",
    "# test_x_mag_phase = np.hstack([np.abs(test_x), np.angle(test_x)])\n",
    "\n",
    "\n",
    "# print(\"Using real imaginary\")\n",
    "# gamut_classification(train_x_real_imag, train_y, test_x_real_imag, test_y)\n",
    "# print(\"\")\n",
    "# print(\"Using mag phase\")\n",
    "# gamut_classification(train_x_mag_phase, train_y, test_x_mag_phase, test_y)\n",
    "\n",
    "# # print(\"\")\n",
    "# print(\"Real only\")\n",
    "# gamut_classification(train_x, train_y, test_x, test_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# We have the following results for QPSK vs BPSK snrs upto 6:\n",
    "# Using real imaginary\n",
    "# Polynomial Kernel, SVM  0.5\n",
    "# RBF Kernel, SVM  0.500714285714\n",
    "# Linear Kernel, SVM  0.499285714286\n",
    "# Random Forests  0.697857142857\n",
    "# AdaBoost  0.855\n",
    "\n",
    "# Using mag phase\n",
    "# Polynomial Kernel, SVM  0.723095238095\n",
    "# RBF Kernel, SVM  0.722142857143\n",
    "# Linear Kernel, SVM  0.567619047619\n",
    "# Random Forests  0.770476190476\n",
    "# AdaBoost  0.848333333333\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Normalization functions\n",
    "def normalize(data):\n",
    "    # Normalizes the norm of the entire vector to 1\n",
    "    data = data.copy()\n",
    "    n, _  = data.shape\n",
    "    if n == 1:\n",
    "        return singular_normalize(data)\n",
    "    \n",
    "    for i in range(n):\n",
    "        data[i, :] = singular_normalize(data[i, :])\n",
    "        \n",
    "    return data\n",
    "    \n",
    "def singular_normalize(data_vector):\n",
    "    # Normalizes one vector to 1\n",
    "    norm = np.linalg.norm(data_vector)\n",
    "    return data_vector / norm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Let us generate AWGN, unit variance, normalize, and compare classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# awgn_data = normalize(np.random.normal(0, 1, (bpsk_features.shape[0], 128)))\n",
    "# bpsk_features_norm = normalize(bpsk_features)\n",
    "# awgn_features = wrapper_cyclo(awgn_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# train_x, train_y, test_x, test_y = create_train_test(bpsk_features_norm, awgn_features)\n",
    "\n",
    "# train_x_real_imag = np.hstack([train_x.real, train_x.imag])\n",
    "# test_x_real_imag = np.hstack([test_x.real, test_x.imag])\n",
    "\n",
    "# train_x_mag_phase = np.hstack([np.abs(train_x), np.angle(train_x)])\n",
    "# test_x_mag_phase = np.hstack([np.abs(test_x), np.angle(test_x)])\n",
    "\n",
    "\n",
    "# print(\"Using real imaginary\")\n",
    "# gamut_classification(train_x_real_imag, train_y, test_x_real_imag, test_y)\n",
    "# print(\"\")\n",
    "# print(\"Using mag phase\")\n",
    "# gamut_classification(train_x_mag_phase, train_y, test_x_mag_phase, test_y)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### We conclude that the classifiers can baseline classify high SNR BPSK vs AWGN. Now we proceed to work with much extended datasets to classify BPSK vs QPSK. These are the ones with the most similar peaks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# def load_dataset(dat_file):\n",
    "#     \"\"\"Input: path to .dat binary data file\n",
    "#        Outputs:\n",
    "#        dataset: The dataset loaded by cPickle\n",
    "#        X: [num_samples, 2, vec_length=128] size 3D array. X[i][0][:] is the real part, X[i][1][:] is the imaginary part\n",
    "#        uid_list: [num_samples] length list. Contains the 'uid' for each sample which can be used to find its label using lbl_map\n",
    "#        lbl_map: Dictionary containing labels for a uid\n",
    "#        lbl: [num_samples] length list. Contains the list of dictionary labels\n",
    "#        \"\"\"\n",
    "#     f = open(dat_file, 'rb')\n",
    "#     dataset = cPickle.load(f, encoding = 'latin-1')\n",
    "    \n",
    "#     Xd = dataset['samples']\n",
    "#     lbl_map = dataset['uid_map']\n",
    "#     total_ids = dataset['total_uids']\n",
    "#     lbl = []\n",
    "#     X = []\n",
    "#     uid_list = []\n",
    "#     for uid in Xd:\n",
    "#         X.append(Xd[uid])\n",
    "#         for j in range(Xd[uid].shape[0]):\n",
    "#             lbl.append((lbl_map[uid]))\n",
    "#             uid_list.append(uid)\n",
    "#     X = np.vstack(X)\n",
    "#     return [dataset, X, uid_list, lbl_map, lbl]\n",
    "\n",
    "# def is_match(target_dict, cand_dict):\n",
    "#     \"\"\"Check if all the key-value pairs in target_dict are present in cand_dict\"\"\"\n",
    "#     for key in target_dict:\n",
    "#         if key != 'channel_model':\n",
    "#             if key not in cand_dict:       \n",
    "#                 return False\n",
    "#             else:\n",
    "#                 got_key = False\n",
    "#                 for inkey in target_dict[key]:  \n",
    "#                     if inkey == cand_dict[key]:\n",
    "#                         got_key = True\n",
    "#                         break\n",
    "                \n",
    "#                 if got_key is False:\n",
    "#                     return False\n",
    "#         else:\n",
    "#             # print key\n",
    "#             # print cand_dict\n",
    "#             if 'channel_model' not in cand_dict:\n",
    "#                 return False\n",
    "#             else:\n",
    "#                 cand_channel_dict = cand_dict['channel_model']\n",
    "#                 if cand_channel_dict['channel_type'] != target_dict[key]:\n",
    "#                     return False\n",
    "#     return True\n",
    "\n",
    "\n",
    "# def assemble_samples(X):\n",
    "#     '''Assemble to desired format containing complex numbers'''\n",
    "#     Y  = np.zeros((X.shape[0], X[0].shape[1]), dtype = 'complex')\n",
    "#     for i in range(X.shape[0]):\n",
    "#         Y[i,:] = X[i][0][:] + 1j*X[i][1][:]\n",
    "#     return Y\n",
    "    \n",
    "# def get_samples(target_dict, dataset):\n",
    "#     X = np.zeros((0,0))\n",
    "#     for uid in dataset['samples']:\n",
    "#         cur_dict = dataset['uid_map'][uid]\n",
    "      \n",
    "#         if is_match(target_dict, cur_dict):\n",
    "#             if X.shape[0] == 0:\n",
    "#                 X= assemble_samples(dataset['samples'][uid])\n",
    "#             else:\n",
    "#                 Y = assemble_samples(dataset['samples'][uid])\n",
    "#                 X = np.vstack([X, Y])\n",
    "            \n",
    "#     return X\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# dat_file = '../../datasets/basic.dat'\n",
    "# [dataset, X, uid_list, lbl_map, lbl] = load_dataset(dat_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# target_dict_bpsk = {}\n",
    "# target_dict_bpsk['mod_type'] = [ 'BPSK_G']\n",
    "\n",
    "\n",
    "# target_dict_qpsk = {}\n",
    "# target_dict_qpsk['mod_type'] = [ 'QPSK_G']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# bpsk_128 = get_samples(target_dict_bpsk, dataset)\n",
    "# qpsk_128 = get_samples(target_dict_qpsk, dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# plt.plot(bpsk_128.real[500])\n",
    "# plt.plot(bpsk_128.imag[500])\n",
    "# plt.title(\"BPSK\")\n",
    "# plt.show()\n",
    "# plt.clf()\n",
    "# plt.plot(qpsk_128.imag[500])\n",
    "# plt.plot(qpsk_128.real[500])\n",
    "# plt.title(\"QPSK\")\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We now have two arrays of split signals, each split snippet is 128 samples long. We now calculate the cyclostationary coefficients of these signals, and then run a gamut of classification techniques to see what works."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# N = 10000\n",
    "# offset = 1000\n",
    "# print(bpsk_128.shape)\n",
    "# print(qpsk_128.shape)\n",
    "# bpsk_features = wrapper_cyclo(bpsk_128)\n",
    "# qpsk_features = wrapper_cyclo(qpsk_128)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# train_x, train_y, test_x, test_y = create_train_test(bpsk_features, qpsk_features)\n",
    "# print(\"Done Creating Training and test set.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# train_x_real_imag = np.hstack([train_x.real, train_x.imag])\n",
    "# test_x_real_imag = np.hstack([test_x.real, test_x.imag])\n",
    "\n",
    "# train_x_mag_phase = np.hstack([np.abs(train_x), np.angle(train_x)])\n",
    "# test_x_mag_phase = np.hstack([np.abs(test_x), np.angle(test_x)])\n",
    "\n",
    "\n",
    "# print(\"Using real imaginary\")\n",
    "# gamut_classification(train_x_real_imag, train_y, test_x_real_imag, test_y)\n",
    "# print(\"\")\n",
    "# print(\"Using mag phase\")\n",
    "# gamut_classification(train_x_mag_phase, train_y, test_x_mag_phase, test_y)\n",
    "\n",
    "# gamut_classification(train_x, train_y, test_x, test_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "''' Using real imaginary \n",
    "Polynomial Kernel, SVM  0.5\n",
    "RBF Kernel, SVM  0.5\n",
    "Linear Kernel, SVM  0.575166666667\n",
    "Random Forests  0.887166666667\n",
    "AdaBoost  0.922166666667\n",
    "\n",
    "Using mag phase\n",
    "Polynomial Kernel, SVM  0.876\n",
    "RBF Kernel, SVM  0.874\n",
    "Linear Kernel, SVM  0.660833333333\n",
    "Random Forests  0.770333333333\n",
    "AdaBoost  1.0 '''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA, NMF\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "def gamut_classification_pca(X, Y, n_features=[16,32,64,128],\n",
    "                            c_options=[1, 10, 100, 1000], n_estimators=[10, 100, 1000],use_svm=True,use_adaboost=True,\n",
    "                            use_k_neighbors=True):\n",
    "    \"\"\"\n",
    "    Depending on passed in Arguments, does dimensionality reduction and then classifies.\n",
    "    \"\"\"\n",
    "    pipe = Pipeline([\n",
    "        ('reduce_dim', PCA()),\n",
    "        ('classify', SVC())\n",
    "    ])\n",
    "    \n",
    "    param_grid = []\n",
    "    \n",
    "    if use_adaboost:\n",
    "        param_grid.append({\n",
    "            'reduce_dim': [PCA(iterated_power=7)],\n",
    "            'reduce_dim__n_components': n_features,\n",
    "            'classify': [AdaBoostClassifier()],\n",
    "            'classify__n_estimators': n_estimators\n",
    "        })\n",
    "    \n",
    "    if use_svm:\n",
    "        param_grid.append({\n",
    "            'reduce_dim': [PCA(iterated_power=7)],\n",
    "            'reduce_dim__n_components': n_features,\n",
    "            'classify': [SVC()],\n",
    "            'classify__C': c_options\n",
    "        })\n",
    "        \n",
    "    if use_k_neighbors:\n",
    "        param_grid.append({\n",
    "            'reduce_dim': [PCA(iterated_power=7)],\n",
    "            'reduce_dim__n_components': n_features,\n",
    "            'classify': [SVC()],\n",
    "            'classify__C': c_options\n",
    "        })\n",
    "        \n",
    "        \n",
    "    grid = GridSearchCV(pipe, n_jobs=1, param_grid=param_grid, verbose=10)\n",
    "    grid.fit(X, Y)\n",
    "    return grid\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# N = 100\n",
    "# offset = 1000\n",
    "# bpsk_features_100 = wrapper_cyclo(bpsk_128[offset: offset + N, :])\n",
    "# qpsk_features_100 = wrapper_cyclo(qpsk_128[offset: offset + N, :])\n",
    "# train_x, train_y, test_x, test_y = create_train_test(bpsk_features_100, qpsk_features_100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# train_x_real_imag = np.hstack([train_x.real, train_x.imag])\n",
    "# test_x_real_imag = np.hstack([test_x.real, test_x.imag])\n",
    "\n",
    "# train_x_mag_phase = np.hstack([np.abs(train_x), np.angle(train_x)])\n",
    "# test_x_mag_phase = np.hstack([np.abs(test_x), np.angle(test_x)])\n",
    "\n",
    "# X_real_imag = np.vstack([train_x_real_imag, test_x_real_imag])\n",
    "# X_mag_phase = np.vstack([train_x_mag_phase, test_x_mag_phase])\n",
    "# Y = np.vstack([train_y, test_y])\n",
    "\n",
    "# grid_real_imag = gamut_classification_pca(X_real_imag, Y.ravel())\n",
    "# grid_mag_phase = gamut_classification_pca(X_mag_phase, Y.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# print(\"Using real imag\")\n",
    "# print(grid_real_imag.best_estimator_)\n",
    "# print(grid_real_imag.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# print(\"Using mag phase\")\n",
    "# print(grid_mag_phase.best_estimator_)\n",
    "# print(grid_mag_phase.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# N = 1000\n",
    "# offset = 1000\n",
    "# bpsk_features_1000 = wrapper_cyclo(bpsk_128[offset: offset + N, :])\n",
    "# qpsk_features_1000 = wrapper_cyclo(qpsk_128[offset: offset + N, :])\n",
    "# train_x, train_y, test_x, test_y = create_train_test(bpsk_features_1000, qpsk_features_1000)\n",
    "\n",
    "# train_x_real_imag = np.hstack([train_x.real, train_x.imag])\n",
    "# test_x_real_imag = np.hstack([test_x.real, test_x.imag])\n",
    "\n",
    "# train_x_mag_phase = np.hstack([np.abs(train_x), np.angle(train_x)])\n",
    "# test_x_mag_phase = np.hstack([np.abs(test_x), np.angle(test_x)])\n",
    "\n",
    "# X_real_imag = np.vstack([train_x_real_imag, test_x_real_imag])\n",
    "# X_mag_phase = np.vstack([train_x_mag_phase, test_x_mag_phase])\n",
    "# Y = np.vstack([train_y, test_y])\n",
    "\n",
    "# grid_real_imag = gamut_classification_pca(X_real_imag, Y.ravel())\n",
    "# grid_mag_phase = gamut_classification_pca(X_mag_phase, Y.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# print(\"Using real imag\")\n",
    "# print(grid_real_imag.best_estimator_)\n",
    "# print(grid_real_imag.best_score_)\n",
    "\n",
    "# print(\"Using mag phase\")\n",
    "# print(grid_mag_phase.best_estimator_)\n",
    "# print(grid_mag_phase.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# bpsk = ds[(\"BPSK\", 18)]\n",
    "# qpsk = ds[(\"QPSK\", 18)]\n",
    "\n",
    "# bpsk = np.add(bpsk[:, 0, :], 1j*bpsk[:, 1, :])\n",
    "# qpsk = np.add(qpsk[:, 0, :], 1j*qpsk[:, 1, :])\n",
    "# bpsk_features = wrapper_cyclo(bpsk)\n",
    "# qpsk_features = wrapper_cyclo(qpsk)\n",
    "# train_x, train_y, test_x, test_y = create_train_test(bpsk_features, qpsk_features)\n",
    "\n",
    "# train_x_real_imag = np.hstack([train_x.real, train_x.imag])\n",
    "# test_x_real_imag = np.hstack([test_x.real, test_x.imag])\n",
    "\n",
    "# train_x_mag_phase = np.hstack([np.abs(train_x), np.angle(train_x)])\n",
    "# test_x_mag_phase = np.hstack([np.abs(test_x), np.angle(test_x)])\n",
    "\n",
    "# X_real_imag = np.vstack([train_x_real_imag, test_x_real_imag])\n",
    "# X_mag_phase = np.vstack([train_x_mag_phase, test_x_mag_phase])\n",
    "# Y = np.vstack([train_y, test_y])\n",
    "\n",
    "# grid_real_imag = gamut_classification_pca(X_real_imag, Y.ravel())\n",
    "# grid_mag_phase = gamut_classification_pca(X_mag_phase, Y.ravel())\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# print(\"Using real imag\")\n",
    "# print(grid_real_imag.best_estimator_)\n",
    "# print(grid_real_imag.best_score_)\n",
    "\n",
    "# print(\"Using mag phase\")\n",
    "# print(grid_mag_phase.best_estimator_)\n",
    "# print(grid_mag_phase.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# # snr_vals = list(map(lambda a: a[1], list(filter(lambda a:a[0] == 'BPSK' and a[1] != 18, list(ds.keys()), ))))\n",
    "# snr_vals = [16,14, 12, 10, 8, 6]\n",
    "\n",
    "# bpsk = ds[(\"BPSK\", 18)]\n",
    "# qpsk = ds[(\"QPSK\", 18)]\n",
    "# for i in snr_vals:\n",
    "#     bpsk = np.vstack([ds[(\"BPSK\", i)], bpsk])\n",
    "#     qpsk = np.vstack([ds[(\"QPSK\", i)], qpsk])\n",
    "\n",
    "# bpsk = np.add(bpsk[:, 0, :], 1j*bpsk[:, 1, :])\n",
    "# qpsk = np.add(qpsk[:, 0, :], 1j*qpsk[:, 1, :])\n",
    "# bpsk_features = wrapper_cyclo(bpsk)\n",
    "# qpsk_features = wrapper_cyclo(qpsk)\n",
    "# train_x, train_y, test_x, test_y = create_train_test(bpsk_features, qpsk_features)\n",
    "\n",
    "# train_x_real_imag = np.hstack([train_x.real, train_x.imag])\n",
    "# test_x_real_imag = np.hstack([test_x.real, test_x.imag])\n",
    "\n",
    "# train_x_mag_phase = np.hstack([np.abs(train_x), np.angle(train_x)])\n",
    "# test_x_mag_phase = np.hstack([np.abs(test_x), np.angle(test_x)])\n",
    "\n",
    "# X_real_imag = np.vstack([train_x_real_imag, test_x_real_imag])\n",
    "# X_mag_phase = np.vstack([train_x_mag_phase, test_x_mag_phase])\n",
    "# Y = np.vstack([train_y, test_y])\n",
    "\n",
    "# grid_real_imag = gamut_classification_pca(X_real_imag, Y.ravel())\n",
    "# grid_mag_phase = gamut_classification_pca(X_mag_phase, Y.ravel())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# print(\"Using real imag\")\n",
    "# print(grid_real_imag.best_estimator_)\n",
    "# print(grid_real_imag.best_score_)\n",
    "\n",
    "# print(\"Using mag phase\")\n",
    "# print(grid_mag_phase.best_estimator_)\n",
    "# print(grid_mag_phase.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We have that using all SNRs lowers effectiveness by 20% for BPSK vs QPSK, instead of just SNR 18.\n",
    "## Let us now use AdaBoost with PCA onto 32/64 dimensions and generate a confusion matrix for all signals with SNR 18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_labels(data, shuffle=False):\n",
    "    \"\"\"\n",
    "    Takes an array of n data arrays and assign labels of i for elements in array i.\n",
    "    \"\"\"\n",
    "    ys = [np.zeros((arr.shape[0], 1)) + i for i, arr in enumerate(data)]\n",
    "    X = np.vstack(data)\n",
    "    Y = np.vstack(ys)\n",
    "    print(X.shape, Y.shape)\n",
    "\n",
    "    # Time to mix the data\n",
    "    if shuffle:\n",
    "        together = np.hstack((X, Y))\n",
    "        np.random.shuffle(together)\n",
    "        X, Y = np.hsplit(together, [together.shape[1] - 1])\n",
    "\n",
    "    return X, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = [(key, value) for key, value in ds.items() if key[1] == 18]\n",
    "labels, data_signal = zip(*data)\n",
    "signals = list(\n",
    "    map(lambda data: data[:, 0, :] + 1j*data[:, 1, :], data_signal)\n",
    ") # Convert into a complex number from I and Q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# X, Y = create_labels(signals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# X_real_imag = np.hstack([X.real, X.imag])\n",
    "\n",
    "# X_mag_phase = np.hstack([np.abs(X), np.angle(X)])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# grid_real_imag = gamut_classification_pca(X_real_imag, Y.ravel(), use_svm=False, n_estimators=[100], n_features=[32, 64, 128, 256])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# grid_real_imag.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "# clf_real_imag = grid_real_imag.best_estimator_\n",
    "# true_y, pred_y = Y, clf_real_imag.predict(X)from sklearn.metrics import confusion_matrix\n",
    "# clf_real_imag = grid_real_imag.best_estimator_\n",
    "# true_y, pred_y = Y, clf_real_imag.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import itertools\n",
    "# import numpy as np\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    print(cm)\n",
    "\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "\n",
    "# # Compute confusion matrix\n",
    "# cnf_matrix = confusion_matrix(true_y, pred_y)\n",
    "# np.set_printoptions(precision=2)\n",
    "\n",
    "# # Plot non-normalized confusion matrix\n",
    "# plt.figure()\n",
    "# plot_confusion_matrix(cnf_matrix, classes=labels,\n",
    "#                       title='Confusion matrix, without normalization')\n",
    "\n",
    "# # Plot normalized confusion matrix\n",
    "# plt.figure()\n",
    "# plot_confusion_matrix(cnf_matrix, classes=labels, normalize=True,\n",
    "#                       title='Normalized confusion matrix')\n",
    "\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# cyclo_coeffs = list(map(wrapper_cyclo, signals))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# X, Y = create_labels(np.stack((signals, cyclo_coeffs)))\n",
    "\n",
    "\n",
    "# X, Y = create_labels(cyclo_coeffs)\n",
    "# X_real_imag = np.hstack([X.real, X.imag])\n",
    "\n",
    "\n",
    "\n",
    "# grid_real_imag = gamut_classification_pca(X_real_imag, Y.ravel(), use_svm=False, n_estimators=[100], n_features=[32, 64, 128])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# print(grid_real_imag.best_estimator_)\n",
    "# print(grid_real_imag.best_score_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# clf = grid_real_imag.best_estimator_\n",
    "# true_y, pred_y = Y.ravel(), clf.predict(X_real_imag).ravel()\n",
    "# # Compute confusion matrix\n",
    "# cnf_matrix = confusion_matrix(true_y, pred_y)\n",
    "# np.set_printoptions(precision=2)\n",
    "\n",
    "# # Plot non-normalized confusion matrix\n",
    "# plt.figure(figsize=(10, 20))\n",
    "# plot_confusion_matrix(cnf_matrix, classes=labels,\n",
    "#                       title='Confusion matrix, without normalization')\n",
    "# plt.show()\n",
    "\n",
    "# # Plot normalized confusion matrix\n",
    "# plt.figure(figsize=(10, 20))\n",
    "# plot_confusion_matrix(cnf_matrix, classes=labels, normalize=True,\n",
    "#                       title='Normalized confusion matrix')\n",
    "\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7000/7000 [00:34<00:00, 203.11it/s]\n",
      "100%|██████████| 7000/7000 [00:34<00:00, 205.05it/s]\n",
      "100%|██████████| 7000/7000 [00:32<00:00, 216.19it/s]\n",
      "100%|██████████| 7000/7000 [00:32<00:00, 214.89it/s]\n",
      "100%|██████████| 7000/7000 [00:32<00:00, 212.32it/s]\n",
      "100%|██████████| 7000/7000 [00:33<00:00, 210.64it/s]\n",
      "100%|██████████| 7000/7000 [00:32<00:00, 213.42it/s]\n",
      "100%|██████████| 7000/7000 [00:33<00:00, 211.97it/s]\n",
      "100%|██████████| 7000/7000 [00:33<00:00, 211.78it/s]\n",
      "100%|██████████| 7000/7000 [00:33<00:00, 206.18it/s]\n",
      "100%|██████████| 7000/7000 [00:34<00:00, 205.86it/s]\n"
     ]
    }
   ],
   "source": [
    "data = [(key, value) for key, value in ds.items() if key[1] >= 6]\n",
    "# labels, data_signal = zip(*data)\n",
    "# signals = list(\n",
    "#     map(lambda data: data[:, 0, :] + 1j*data[:, 1, :], data_signal)\n",
    "# ) # Convert into a complex number from I and Q\n",
    "\n",
    "signals = []\n",
    "unique_keys = []\n",
    "for key in data:\n",
    "    if key[0][0] not in unique_keys:\n",
    "        unique_keys.append(key[0][0])\n",
    "for unique_key in unique_keys:\n",
    "    X = np.zeros((0,0), dtype = 'complex')        \n",
    "\n",
    "    for s in data:\n",
    "        if s[0][0] == unique_key:\n",
    "#             print(s[0][0])\n",
    "            if X.shape[0] == 0:\n",
    "                X = s[1][:,0] + 1j*s[1][:,1]\n",
    "            else:                \n",
    "                Y =  s[1][:,0] + 1j*s[1][:,1]\n",
    "#                 print(Y.shape)\n",
    "                X = np.vstack([X, Y])\n",
    "#     print(X.shape)\n",
    "    signals.append(X)\n",
    "        \n",
    "            \n",
    "        \n",
    "cyclo_coeffs = list(map(wrapper_cyclo, signals))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(77000, 128) (77000, 1)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAD8CAYAAACb4nSYAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fbcbcadb470>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def create_labels(data, shuffle=False):\n",
    "    \"\"\"\n",
    "    Takes an array of n data arrays and assign labels of i for elements in array i.\n",
    "    \"\"\"\n",
    "    ys = [np.zeros((arr.shape[0], 1)) + i for i, arr in enumerate(data)]\n",
    "    X = np.vstack(data)\n",
    "    Y = np.vstack(ys)\n",
    "    print(X.shape, Y.shape)\n",
    "\n",
    "    # Time to mix the data\n",
    "    if shuffle:\n",
    "        together = np.hstack((X, Y))\n",
    "        np.random.shuffle(together)\n",
    "        X, Y = np.hsplit(together, [together.shape[1] - 1])\n",
    "\n",
    "    return X, Y\n",
    "\n",
    "X, Y = create_labels(cyclo_coeffs)\n",
    "# Xs, Y = create_labels(signals)\n",
    "\n",
    "X_mag_phase = np.hstack([np.abs(X), np.angle(X)])\n",
    "\n",
    "# X_mag_phase = np.hstack([np.abs(X), np.angle(X), np.abs(Xs), np.angle(Xs)])\n",
    "# print(X_mag_phase.shape)\n",
    "\n",
    "plt.plot(Y)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 15 candidates, totalling 45 fits\n",
      "[CV] classify=AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None,\n",
      "          learning_rate=1.0, n_estimators=50, random_state=None), classify__n_estimators=100, reduce_dim=PCA(copy=True, iterated_power=7, n_components=None, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), reduce_dim__n_components=32 \n",
      "[CV]  classify=AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None,\n",
      "          learning_rate=1.0, n_estimators=50, random_state=None), classify__n_estimators=100, reduce_dim=PCA(copy=True, iterated_power=7, n_components=None, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), reduce_dim__n_components=32, score=0.19992989016125262, total=  22.2s\n",
      "[CV] classify=AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None,\n",
      "          learning_rate=1.0, n_estimators=100, random_state=None), classify__n_estimators=100, reduce_dim=PCA(copy=True, iterated_power=7, n_components=32, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), reduce_dim__n_components=32 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:   23.8s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  classify=AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None,\n",
      "          learning_rate=1.0, n_estimators=100, random_state=None), classify__n_estimators=100, reduce_dim=PCA(copy=True, iterated_power=7, n_components=32, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), reduce_dim__n_components=32, score=0.19409266258816193, total=  21.8s\n",
      "[CV] classify=AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None,\n",
      "          learning_rate=1.0, n_estimators=100, random_state=None), classify__n_estimators=100, reduce_dim=PCA(copy=True, iterated_power=7, n_components=32, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), reduce_dim__n_components=32 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:   47.2s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  classify=AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None,\n",
      "          learning_rate=1.0, n_estimators=100, random_state=None), classify__n_estimators=100, reduce_dim=PCA(copy=True, iterated_power=7, n_components=32, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), reduce_dim__n_components=32, score=0.21077036979308733, total=  21.9s\n",
      "[CV] classify=AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None,\n",
      "          learning_rate=1.0, n_estimators=100, random_state=None), classify__n_estimators=100, reduce_dim=PCA(copy=True, iterated_power=7, n_components=32, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), reduce_dim__n_components=64 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:  1.2min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  classify=AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None,\n",
      "          learning_rate=1.0, n_estimators=100, random_state=None), classify__n_estimators=100, reduce_dim=PCA(copy=True, iterated_power=7, n_components=32, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), reduce_dim__n_components=64, score=0.3093012386071512, total=  41.0s\n",
      "[CV] classify=AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None,\n",
      "          learning_rate=1.0, n_estimators=100, random_state=None), classify__n_estimators=100, reduce_dim=PCA(copy=True, iterated_power=7, n_components=64, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), reduce_dim__n_components=64 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:  1.9min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  classify=AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None,\n",
      "          learning_rate=1.0, n_estimators=100, random_state=None), classify__n_estimators=100, reduce_dim=PCA(copy=True, iterated_power=7, n_components=64, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), reduce_dim__n_components=64, score=0.302224993180844, total=  40.7s\n",
      "[CV] classify=AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None,\n",
      "          learning_rate=1.0, n_estimators=100, random_state=None), classify__n_estimators=100, reduce_dim=PCA(copy=True, iterated_power=7, n_components=64, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), reduce_dim__n_components=64 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:  2.6min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  classify=AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None,\n",
      "          learning_rate=1.0, n_estimators=100, random_state=None), classify__n_estimators=100, reduce_dim=PCA(copy=True, iterated_power=7, n_components=64, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), reduce_dim__n_components=64, score=0.35307641351361885, total=  40.5s\n",
      "[CV] classify=AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None,\n",
      "          learning_rate=1.0, n_estimators=100, random_state=None), classify__n_estimators=100, reduce_dim=PCA(copy=True, iterated_power=7, n_components=64, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), reduce_dim__n_components=128 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   6 out of   6 | elapsed:  3.3min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  classify=AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None,\n",
      "          learning_rate=1.0, n_estimators=100, random_state=None), classify__n_estimators=100, reduce_dim=PCA(copy=True, iterated_power=7, n_components=64, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), reduce_dim__n_components=128, score=0.3606372205343928, total= 1.2min\n",
      "[CV] classify=AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None,\n",
      "          learning_rate=1.0, n_estimators=100, random_state=None), classify__n_estimators=100, reduce_dim=PCA(copy=True, iterated_power=7, n_components=128, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), reduce_dim__n_components=128 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:  4.5min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  classify=AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None,\n",
      "          learning_rate=1.0, n_estimators=100, random_state=None), classify__n_estimators=100, reduce_dim=PCA(copy=True, iterated_power=7, n_components=128, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), reduce_dim__n_components=128, score=0.34115263219420955, total= 1.2min\n",
      "[CV] classify=AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None,\n",
      "          learning_rate=1.0, n_estimators=100, random_state=None), classify__n_estimators=100, reduce_dim=PCA(copy=True, iterated_power=7, n_components=128, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), reduce_dim__n_components=128 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   8 out of   8 | elapsed:  5.7min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  classify=AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None,\n",
      "          learning_rate=1.0, n_estimators=100, random_state=None), classify__n_estimators=100, reduce_dim=PCA(copy=True, iterated_power=7, n_components=128, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), reduce_dim__n_components=128, score=0.3569341074698983, total= 1.2min\n",
      "[CV] classify=SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',\n",
      "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=False), classify__C=1, reduce_dim=PCA(copy=True, iterated_power=7, n_components=None, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), reduce_dim__n_components=32 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:  6.9min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  classify=SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',\n",
      "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=False), classify__C=1, reduce_dim=PCA(copy=True, iterated_power=7, n_components=None, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), reduce_dim__n_components=32, score=0.3697904494819662, total= 4.5min\n",
      "[CV] classify=SVC(C=1, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',\n",
      "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=False), classify__C=1, reduce_dim=PCA(copy=True, iterated_power=7, n_components=32, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), reduce_dim__n_components=32 \n",
      "[CV]  classify=SVC(C=1, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',\n",
      "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=False), classify__C=1, reduce_dim=PCA(copy=True, iterated_power=7, n_components=32, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), reduce_dim__n_components=32, score=0.3846783306706153, total= 4.5min\n",
      "[CV] classify=SVC(C=1, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',\n",
      "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=False), classify__C=1, reduce_dim=PCA(copy=True, iterated_power=7, n_components=32, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), reduce_dim__n_components=32 \n",
      "[CV]  classify=SVC(C=1, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',\n",
      "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=False), classify__C=1, reduce_dim=PCA(copy=True, iterated_power=7, n_components=32, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), reduce_dim__n_components=32, score=0.3814441024042396, total= 4.4min\n",
      "[CV] classify=SVC(C=1, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',\n",
      "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=False), classify__C=1, reduce_dim=PCA(copy=True, iterated_power=7, n_components=32, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), reduce_dim__n_components=64 \n",
      "[CV]  classify=SVC(C=1, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',\n",
      "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=False), classify__C=1, reduce_dim=PCA(copy=True, iterated_power=7, n_components=32, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), reduce_dim__n_components=64, score=0.3639869128301005, total= 6.8min\n",
      "[CV] classify=SVC(C=1, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',\n",
      "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=False), classify__C=1, reduce_dim=PCA(copy=True, iterated_power=7, n_components=64, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), reduce_dim__n_components=64 \n",
      "[CV]  classify=SVC(C=1, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',\n",
      "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=False), classify__C=1, reduce_dim=PCA(copy=True, iterated_power=7, n_components=64, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), reduce_dim__n_components=64, score=0.3758718778007248, total= 7.1min\n",
      "[CV] classify=SVC(C=1, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',\n",
      "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=False), classify__C=1, reduce_dim=PCA(copy=True, iterated_power=7, n_components=64, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), reduce_dim__n_components=64 \n",
      "[CV]  classify=SVC(C=1, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',\n",
      "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=False), classify__C=1, reduce_dim=PCA(copy=True, iterated_power=7, n_components=64, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), reduce_dim__n_components=64, score=0.3712738183376846, total= 6.8min\n",
      "[CV] classify=SVC(C=1, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',\n",
      "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=False), classify__C=1, reduce_dim=PCA(copy=True, iterated_power=7, n_components=64, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), reduce_dim__n_components=128 \n",
      "[CV]  classify=SVC(C=1, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',\n",
      "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=False), classify__C=1, reduce_dim=PCA(copy=True, iterated_power=7, n_components=64, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), reduce_dim__n_components=128, score=0.34977019552855027, total=10.0min\n",
      "[CV] classify=SVC(C=1, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',\n",
      "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=False), classify__C=1, reduce_dim=PCA(copy=True, iterated_power=7, n_components=128, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), reduce_dim__n_components=128 \n",
      "[CV]  classify=SVC(C=1, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',\n",
      "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=False), classify__C=1, reduce_dim=PCA(copy=True, iterated_power=7, n_components=128, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), reduce_dim__n_components=128, score=0.3587265713283716, total= 9.8min\n",
      "[CV] classify=SVC(C=1, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',\n",
      "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=False), classify__C=1, reduce_dim=PCA(copy=True, iterated_power=7, n_components=128, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), reduce_dim__n_components=128 \n",
      "[CV]  classify=SVC(C=1, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',\n",
      "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=False), classify__C=1, reduce_dim=PCA(copy=True, iterated_power=7, n_components=128, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), reduce_dim__n_components=128, score=0.35482991076647313, total= 9.7min\n",
      "[CV] classify=SVC(C=1, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',\n",
      "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=False), classify__C=10, reduce_dim=PCA(copy=True, iterated_power=7, n_components=128, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), reduce_dim__n_components=32 \n",
      "[CV]  classify=SVC(C=1, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',\n",
      "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=False), classify__C=10, reduce_dim=PCA(copy=True, iterated_power=7, n_components=128, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), reduce_dim__n_components=32, score=0.394328893043546, total= 4.7min\n",
      "[CV] classify=SVC(C=10, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',\n",
      "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=False), classify__C=10, reduce_dim=PCA(copy=True, iterated_power=7, n_components=32, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), reduce_dim__n_components=32 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  classify=SVC(C=10, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',\n",
      "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=False), classify__C=10, reduce_dim=PCA(copy=True, iterated_power=7, n_components=32, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), reduce_dim__n_components=32, score=0.4019015703542064, total= 4.8min\n",
      "[CV] classify=SVC(C=10, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',\n",
      "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=False), classify__C=10, reduce_dim=PCA(copy=True, iterated_power=7, n_components=32, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), reduce_dim__n_components=32 \n",
      "[CV]  classify=SVC(C=10, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',\n",
      "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=False), classify__C=10, reduce_dim=PCA(copy=True, iterated_power=7, n_components=32, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), reduce_dim__n_components=32, score=0.4063437633947707, total= 4.8min\n",
      "[CV] classify=SVC(C=10, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',\n",
      "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=False), classify__C=10, reduce_dim=PCA(copy=True, iterated_power=7, n_components=32, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), reduce_dim__n_components=64 \n",
      "[CV]  classify=SVC(C=10, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',\n",
      "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=False), classify__C=10, reduce_dim=PCA(copy=True, iterated_power=7, n_components=32, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), reduce_dim__n_components=64, score=0.3853704136480486, total= 7.2min\n",
      "[CV] classify=SVC(C=10, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',\n",
      "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=False), classify__C=10, reduce_dim=PCA(copy=True, iterated_power=7, n_components=64, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), reduce_dim__n_components=64 \n",
      "[CV]  classify=SVC(C=10, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',\n",
      "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=False), classify__C=10, reduce_dim=PCA(copy=True, iterated_power=7, n_components=64, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), reduce_dim__n_components=64, score=0.3970697112574524, total= 7.4min\n",
      "[CV] classify=SVC(C=10, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',\n",
      "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=False), classify__C=10, reduce_dim=PCA(copy=True, iterated_power=7, n_components=64, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), reduce_dim__n_components=64 \n",
      "[CV]  classify=SVC(C=10, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',\n",
      "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=False), classify__C=10, reduce_dim=PCA(copy=True, iterated_power=7, n_components=64, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), reduce_dim__n_components=64, score=0.3989790749327826, total= 7.4min\n",
      "[CV] classify=SVC(C=10, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',\n",
      "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=False), classify__C=10, reduce_dim=PCA(copy=True, iterated_power=7, n_components=64, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), reduce_dim__n_components=128 \n",
      "[CV]  classify=SVC(C=10, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',\n",
      "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=False), classify__C=10, reduce_dim=PCA(copy=True, iterated_power=7, n_components=64, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), reduce_dim__n_components=128, score=0.3735685907922412, total=10.6min\n",
      "[CV] classify=SVC(C=10, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',\n",
      "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=False), classify__C=10, reduce_dim=PCA(copy=True, iterated_power=7, n_components=128, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), reduce_dim__n_components=128 \n",
      "[CV]  classify=SVC(C=10, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',\n",
      "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=False), classify__C=10, reduce_dim=PCA(copy=True, iterated_power=7, n_components=128, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), reduce_dim__n_components=128, score=0.38043097065814596, total=10.8min\n",
      "[CV] classify=SVC(C=10, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',\n",
      "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=False), classify__C=10, reduce_dim=PCA(copy=True, iterated_power=7, n_components=128, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), reduce_dim__n_components=128 \n",
      "[CV]  classify=SVC(C=10, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',\n",
      "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=False), classify__C=10, reduce_dim=PCA(copy=True, iterated_power=7, n_components=128, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), reduce_dim__n_components=128, score=0.38257413396719014, total=10.6min\n",
      "[CV] classify=SVC(C=10, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',\n",
      "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=False), classify__C=100, reduce_dim=PCA(copy=True, iterated_power=7, n_components=128, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), reduce_dim__n_components=32 \n",
      "[CV]  classify=SVC(C=10, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',\n",
      "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=False), classify__C=100, reduce_dim=PCA(copy=True, iterated_power=7, n_components=128, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), reduce_dim__n_components=32, score=0.4117005530887279, total= 5.4min\n",
      "[CV] classify=SVC(C=100, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',\n",
      "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=False), classify__C=100, reduce_dim=PCA(copy=True, iterated_power=7, n_components=32, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), reduce_dim__n_components=32 \n",
      "[CV]  classify=SVC(C=100, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',\n",
      "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=False), classify__C=100, reduce_dim=PCA(copy=True, iterated_power=7, n_components=32, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), reduce_dim__n_components=32, score=0.410552156801621, total= 5.5min\n",
      "[CV] classify=SVC(C=100, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',\n",
      "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=False), classify__C=100, reduce_dim=PCA(copy=True, iterated_power=7, n_components=32, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), reduce_dim__n_components=32 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  classify=SVC(C=100, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',\n",
      "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=False), classify__C=100, reduce_dim=PCA(copy=True, iterated_power=7, n_components=32, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), reduce_dim__n_components=32, score=0.4070841289015314, total= 5.6min\n",
      "[CV] classify=SVC(C=100, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',\n",
      "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=False), classify__C=100, reduce_dim=PCA(copy=True, iterated_power=7, n_components=32, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), reduce_dim__n_components=64 \n",
      "[CV]  classify=SVC(C=100, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',\n",
      "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=False), classify__C=100, reduce_dim=PCA(copy=True, iterated_power=7, n_components=32, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), reduce_dim__n_components=64, score=0.4070265638389032, total= 7.6min\n",
      "[CV] classify=SVC(C=100, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',\n",
      "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=False), classify__C=100, reduce_dim=PCA(copy=True, iterated_power=7, n_components=64, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), reduce_dim__n_components=64 \n",
      "[CV]  classify=SVC(C=100, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',\n",
      "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=False), classify__C=100, reduce_dim=PCA(copy=True, iterated_power=7, n_components=64, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), reduce_dim__n_components=64, score=0.41292911974437907, total= 7.6min\n",
      "[CV] classify=SVC(C=100, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',\n",
      "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=False), classify__C=100, reduce_dim=PCA(copy=True, iterated_power=7, n_components=64, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), reduce_dim__n_components=64 \n",
      "[CV]  classify=SVC(C=100, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',\n",
      "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=False), classify__C=100, reduce_dim=PCA(copy=True, iterated_power=7, n_components=64, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), reduce_dim__n_components=64, score=0.40852589330943384, total= 7.8min\n",
      "[CV] classify=SVC(C=100, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',\n",
      "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=False), classify__C=100, reduce_dim=PCA(copy=True, iterated_power=7, n_components=64, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), reduce_dim__n_components=128 \n",
      "[CV]  classify=SVC(C=100, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',\n",
      "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=False), classify__C=100, reduce_dim=PCA(copy=True, iterated_power=7, n_components=64, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), reduce_dim__n_components=128, score=0.3907844511957623, total=10.3min\n",
      "[CV] classify=SVC(C=100, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',\n",
      "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=False), classify__C=100, reduce_dim=PCA(copy=True, iterated_power=7, n_components=128, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), reduce_dim__n_components=128 \n",
      "[CV]  classify=SVC(C=100, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',\n",
      "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=False), classify__C=100, reduce_dim=PCA(copy=True, iterated_power=7, n_components=128, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), reduce_dim__n_components=128, score=0.3989011417215446, total=10.8min\n",
      "[CV] classify=SVC(C=100, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',\n",
      "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=False), classify__C=100, reduce_dim=PCA(copy=True, iterated_power=7, n_components=128, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), reduce_dim__n_components=128 \n",
      "[CV]  classify=SVC(C=100, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',\n",
      "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=False), classify__C=100, reduce_dim=PCA(copy=True, iterated_power=7, n_components=128, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), reduce_dim__n_components=128, score=0.4000701398901142, total=10.5min\n",
      "[CV] classify=SVC(C=100, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',\n",
      "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=False), classify__C=1000, reduce_dim=PCA(copy=True, iterated_power=7, n_components=128, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), reduce_dim__n_components=32 \n",
      "[CV]  classify=SVC(C=100, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',\n",
      "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=False), classify__C=1000, reduce_dim=PCA(copy=True, iterated_power=7, n_components=128, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), reduce_dim__n_components=32, score=0.41547869439900287, total= 9.3min\n",
      "[CV] classify=SVC(C=1000, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',\n",
      "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=False), classify__C=1000, reduce_dim=PCA(copy=True, iterated_power=7, n_components=32, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), reduce_dim__n_components=32 \n",
      "[CV]  classify=SVC(C=1000, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',\n",
      "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=False), classify__C=1000, reduce_dim=PCA(copy=True, iterated_power=7, n_components=32, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), reduce_dim__n_components=32, score=0.4098897245060983, total= 9.6min\n",
      "[CV] classify=SVC(C=1000, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',\n",
      "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=False), classify__C=1000, reduce_dim=PCA(copy=True, iterated_power=7, n_components=32, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), reduce_dim__n_components=32 \n",
      "[CV]  classify=SVC(C=1000, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',\n",
      "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=False), classify__C=1000, reduce_dim=PCA(copy=True, iterated_power=7, n_components=32, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), reduce_dim__n_components=32, score=0.4045123329306784, total= 9.5min\n",
      "[CV] classify=SVC(C=1000, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',\n",
      "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=False), classify__C=1000, reduce_dim=PCA(copy=True, iterated_power=7, n_components=32, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), reduce_dim__n_components=64 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  classify=SVC(C=1000, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',\n",
      "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=False), classify__C=1000, reduce_dim=PCA(copy=True, iterated_power=7, n_components=32, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), reduce_dim__n_components=64, score=0.4176988392926696, total=10.7min\n",
      "[CV] classify=SVC(C=1000, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',\n",
      "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=False), classify__C=1000, reduce_dim=PCA(copy=True, iterated_power=7, n_components=64, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), reduce_dim__n_components=64 \n",
      "[CV]  classify=SVC(C=1000, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',\n",
      "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=False), classify__C=1000, reduce_dim=PCA(copy=True, iterated_power=7, n_components=64, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), reduce_dim__n_components=64, score=0.41756614581303825, total=11.4min\n",
      "[CV] classify=SVC(C=1000, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',\n",
      "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=False), classify__C=1000, reduce_dim=PCA(copy=True, iterated_power=7, n_components=64, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), reduce_dim__n_components=64 \n",
      "[CV]  classify=SVC(C=1000, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',\n",
      "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=False), classify__C=1000, reduce_dim=PCA(copy=True, iterated_power=7, n_components=64, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), reduce_dim__n_components=64, score=0.40798036083076805, total=11.2min\n",
      "[CV] classify=SVC(C=1000, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',\n",
      "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=False), classify__C=1000, reduce_dim=PCA(copy=True, iterated_power=7, n_components=64, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), reduce_dim__n_components=128 \n",
      "[CV]  classify=SVC(C=1000, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',\n",
      "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=False), classify__C=1000, reduce_dim=PCA(copy=True, iterated_power=7, n_components=64, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), reduce_dim__n_components=128, score=0.4117395029991431, total=12.8min\n",
      "[CV] classify=SVC(C=1000, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',\n",
      "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=False), classify__C=1000, reduce_dim=PCA(copy=True, iterated_power=7, n_components=128, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), reduce_dim__n_components=128 \n",
      "[CV]  classify=SVC(C=1000, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',\n",
      "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=False), classify__C=1000, reduce_dim=PCA(copy=True, iterated_power=7, n_components=128, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), reduce_dim__n_components=128, score=0.41320188598371194, total=13.7min\n",
      "[CV] classify=SVC(C=1000, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',\n",
      "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=False), classify__C=1000, reduce_dim=PCA(copy=True, iterated_power=7, n_components=128, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), reduce_dim__n_components=128 \n",
      "[CV]  classify=SVC(C=1000, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',\n",
      "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=False), classify__C=1000, reduce_dim=PCA(copy=True, iterated_power=7, n_components=128, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), reduce_dim__n_components=128, score=0.40466819935315435, total=13.8min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  45 out of  45 | elapsed: 470.3min finished\n"
     ]
    }
   ],
   "source": [
    "grid_mag_phase = gamut_classification_pca(X_mag_phase, Y.ravel(), use_svm=False, n_estimators=[100], n_features=[32, 64, 128])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(memory=None,\n",
      "     steps=[('reduce_dim', PCA(copy=True, iterated_power=7, n_components=64, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False)), ('classify', SVC(C=1000, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',\n",
      "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=False))])\n",
      "0.414415584416\n"
     ]
    }
   ],
   "source": [
    "print(grid_mag_phase.best_estimator_)\n",
    "print(grid_mag_phase.best_score_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(memory=None,\n",
      "     steps=[('reduce_dim', PCA(copy=True, iterated_power=7, n_components=64, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False)), ('classify', SVC(C=1000, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',\n",
      "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=False))])\n",
      "0.863075\n"
     ]
    }
   ],
   "source": [
    "print(grid_mag_phase.best_estimator_)\n",
    "# clf = grid_mag_phase.best_estimator_\n",
    "# true_y, pred_y = Y.ravel(), clf.predict(X_mag_phase).ravel()\n",
    "# # Compute confusion matrix\n",
    "# cnf_matrix = confusion_matrix(true_y, pred_y)\n",
    "# np.set_printoptions(precision=2)\n",
    "\n",
    "# # Plot non-normalized confusion matrix\n",
    "# plt.figure(figsize=(10, 20))\n",
    "# plot_confusion_matrix(cnf_matrix, classes=labels,\n",
    "#                       title='Confusion matrix, without normalization')\n",
    "# plt.show()\n",
    "\n",
    "# # Plot normalized confusion matrix\n",
    "# plt.figure(figsize=(10, 20))\n",
    "# plot_confusion_matrix(cnf_matrix, classes=labels, normalize=True,\n",
    "#                       title='Normalized confusion matrix')\n",
    "\n",
    "# plt.show()\n",
    "cntc = 0\n",
    "lim =40000\n",
    "for i in range(lim):\n",
    "       if true_y[i] == pred_y[i]:\n",
    "             cntc += 1\n",
    "print(cntc/lim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "X_real_imag = np.hstack([X.real, X.imag])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 15 candidates, totalling 45 fits\n",
      "[CV] classify=AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None,\n",
      "          learning_rate=1.0, n_estimators=50, random_state=None), classify__n_estimators=100, reduce_dim=PCA(copy=True, iterated_power=7, n_components=None, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), reduce_dim__n_components=32 \n",
      "[CV]  classify=AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None,\n",
      "          learning_rate=1.0, n_estimators=50, random_state=None), classify__n_estimators=100, reduce_dim=PCA(copy=True, iterated_power=7, n_components=None, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), reduce_dim__n_components=32, score=0.20845992054218276, total=  16.6s\n",
      "[CV] classify=AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None,\n",
      "          learning_rate=1.0, n_estimators=100, random_state=None), classify__n_estimators=100, reduce_dim=PCA(copy=True, iterated_power=7, n_components=32, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), reduce_dim__n_components=32 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:   18.3s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  classify=AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None,\n",
      "          learning_rate=1.0, n_estimators=100, random_state=None), classify__n_estimators=100, reduce_dim=PCA(copy=True, iterated_power=7, n_components=32, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), reduce_dim__n_components=32, score=0.3033160581381756, total=  18.3s\n",
      "[CV] classify=AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None,\n",
      "          learning_rate=1.0, n_estimators=100, random_state=None), classify__n_estimators=100, reduce_dim=PCA(copy=True, iterated_power=7, n_components=32, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), reduce_dim__n_components=32 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:   38.7s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  classify=AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None,\n",
      "          learning_rate=1.0, n_estimators=100, random_state=None), classify__n_estimators=100, reduce_dim=PCA(copy=True, iterated_power=7, n_components=32, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), reduce_dim__n_components=32, score=0.3029653586876047, total=  18.4s\n",
      "[CV] classify=AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None,\n",
      "          learning_rate=1.0, n_estimators=100, random_state=None), classify__n_estimators=100, reduce_dim=PCA(copy=True, iterated_power=7, n_components=32, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), reduce_dim__n_components=64 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:   58.8s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  classify=AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None,\n",
      "          learning_rate=1.0, n_estimators=100, random_state=None), classify__n_estimators=100, reduce_dim=PCA(copy=True, iterated_power=7, n_components=32, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), reduce_dim__n_components=64, score=0.2738957700397289, total=  32.2s\n",
      "[CV] classify=AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None,\n",
      "          learning_rate=1.0, n_estimators=100, random_state=None), classify__n_estimators=100, reduce_dim=PCA(copy=True, iterated_power=7, n_components=64, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), reduce_dim__n_components=64 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:  1.5min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  classify=AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None,\n",
      "          learning_rate=1.0, n_estimators=100, random_state=None), classify__n_estimators=100, reduce_dim=PCA(copy=True, iterated_power=7, n_components=64, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), reduce_dim__n_components=64, score=0.3033160581381756, total=  31.5s\n",
      "[CV] classify=AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None,\n",
      "          learning_rate=1.0, n_estimators=100, random_state=None), classify__n_estimators=100, reduce_dim=PCA(copy=True, iterated_power=7, n_components=64, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), reduce_dim__n_components=64 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:  2.1min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  classify=AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None,\n",
      "          learning_rate=1.0, n_estimators=100, random_state=None), classify__n_estimators=100, reduce_dim=PCA(copy=True, iterated_power=7, n_components=64, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), reduce_dim__n_components=64, score=0.3029653586876047, total=  31.9s\n",
      "[CV] classify=AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None,\n",
      "          learning_rate=1.0, n_estimators=100, random_state=None), classify__n_estimators=100, reduce_dim=PCA(copy=True, iterated_power=7, n_components=64, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), reduce_dim__n_components=128 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   6 out of   6 | elapsed:  2.7min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  classify=AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None,\n",
      "          learning_rate=1.0, n_estimators=100, random_state=None), classify__n_estimators=100, reduce_dim=PCA(copy=True, iterated_power=7, n_components=64, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), reduce_dim__n_components=128, score=0.20179948586118251, total= 1.1min\n",
      "[CV] classify=AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None,\n",
      "          learning_rate=1.0, n_estimators=100, random_state=None), classify__n_estimators=100, reduce_dim=PCA(copy=True, iterated_power=7, n_components=128, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), reduce_dim__n_components=128 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:  3.7min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  classify=AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None,\n",
      "          learning_rate=1.0, n_estimators=100, random_state=None), classify__n_estimators=100, reduce_dim=PCA(copy=True, iterated_power=7, n_components=128, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), reduce_dim__n_components=128, score=0.3033160581381756, total= 1.0min\n",
      "[CV] classify=AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None,\n",
      "          learning_rate=1.0, n_estimators=100, random_state=None), classify__n_estimators=100, reduce_dim=PCA(copy=True, iterated_power=7, n_components=128, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), reduce_dim__n_components=128 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   8 out of   8 | elapsed:  4.8min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  classify=AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None,\n",
      "          learning_rate=1.0, n_estimators=100, random_state=None), classify__n_estimators=100, reduce_dim=PCA(copy=True, iterated_power=7, n_components=128, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), reduce_dim__n_components=128, score=0.3029653586876047, total= 1.0min\n",
      "[CV] classify=SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',\n",
      "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=False), classify__C=1, reduce_dim=PCA(copy=True, iterated_power=7, n_components=None, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), reduce_dim__n_components=32 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:  5.8min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  classify=SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',\n",
      "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=False), classify__C=1, reduce_dim=PCA(copy=True, iterated_power=7, n_components=None, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), reduce_dim__n_components=32, score=0.29329282542650154, total= 6.4min\n",
      "[CV] classify=SVC(C=1, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',\n",
      "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=False), classify__C=1, reduce_dim=PCA(copy=True, iterated_power=7, n_components=32, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), reduce_dim__n_components=32 \n",
      "[CV]  classify=SVC(C=1, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',\n",
      "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=False), classify__C=1, reduce_dim=PCA(copy=True, iterated_power=7, n_components=32, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), reduce_dim__n_components=32, score=0.29084674434010055, total= 6.5min\n",
      "[CV] classify=SVC(C=1, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',\n",
      "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=False), classify__C=1, reduce_dim=PCA(copy=True, iterated_power=7, n_components=32, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), reduce_dim__n_components=32 \n",
      "[CV]  classify=SVC(C=1, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',\n",
      "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=False), classify__C=1, reduce_dim=PCA(copy=True, iterated_power=7, n_components=32, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), reduce_dim__n_components=32, score=0.2926781748041928, total= 6.3min\n",
      "[CV] classify=SVC(C=1, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',\n",
      "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=False), classify__C=1, reduce_dim=PCA(copy=True, iterated_power=7, n_components=32, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), reduce_dim__n_components=64 \n",
      "[CV]  classify=SVC(C=1, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',\n",
      "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=False), classify__C=1, reduce_dim=PCA(copy=True, iterated_power=7, n_components=32, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), reduce_dim__n_components=64, score=0.261626548258939, total= 9.7min\n",
      "[CV] classify=SVC(C=1, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',\n",
      "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=False), classify__C=1, reduce_dim=PCA(copy=True, iterated_power=7, n_components=64, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), reduce_dim__n_components=64 \n",
      "[CV]  classify=SVC(C=1, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',\n",
      "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=False), classify__C=1, reduce_dim=PCA(copy=True, iterated_power=7, n_components=64, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), reduce_dim__n_components=64, score=0.2585044616763434, total= 9.8min\n",
      "[CV] classify=SVC(C=1, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',\n",
      "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=False), classify__C=1, reduce_dim=PCA(copy=True, iterated_power=7, n_components=64, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), reduce_dim__n_components=64 \n",
      "[CV]  classify=SVC(C=1, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',\n",
      "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=False), classify__C=1, reduce_dim=PCA(copy=True, iterated_power=7, n_components=64, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), reduce_dim__n_components=64, score=0.2603358921404356, total= 9.7min\n",
      "[CV] classify=SVC(C=1, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',\n",
      "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=False), classify__C=1, reduce_dim=PCA(copy=True, iterated_power=7, n_components=64, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), reduce_dim__n_components=128 \n",
      "[CV]  classify=SVC(C=1, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',\n",
      "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=False), classify__C=1, reduce_dim=PCA(copy=True, iterated_power=7, n_components=64, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), reduce_dim__n_components=128, score=0.34973124561813507, total=17.8min\n",
      "[CV] classify=SVC(C=1, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',\n",
      "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=False), classify__C=1, reduce_dim=PCA(copy=True, iterated_power=7, n_components=128, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), reduce_dim__n_components=128 \n",
      "[CV]  classify=SVC(C=1, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',\n",
      "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=False), classify__C=1, reduce_dim=PCA(copy=True, iterated_power=7, n_components=128, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), reduce_dim__n_components=128, score=0.34664692358648636, total=17.7min\n",
      "[CV] classify=SVC(C=1, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',\n",
      "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=False), classify__C=1, reduce_dim=PCA(copy=True, iterated_power=7, n_components=128, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), reduce_dim__n_components=128 \n",
      "[CV]  classify=SVC(C=1, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',\n",
      "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=False), classify__C=1, reduce_dim=PCA(copy=True, iterated_power=7, n_components=128, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), reduce_dim__n_components=128, score=0.3482055878112458, total=17.4min\n",
      "[CV] classify=SVC(C=1, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',\n",
      "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=False), classify__C=10, reduce_dim=PCA(copy=True, iterated_power=7, n_components=128, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), reduce_dim__n_components=32 \n",
      "[CV]  classify=SVC(C=1, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',\n",
      "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=False), classify__C=10, reduce_dim=PCA(copy=True, iterated_power=7, n_components=128, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), reduce_dim__n_components=32, score=0.29340967515774713, total= 6.3min\n",
      "[CV] classify=SVC(C=10, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',\n",
      "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=False), classify__C=10, reduce_dim=PCA(copy=True, iterated_power=7, n_components=32, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), reduce_dim__n_components=32 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  classify=SVC(C=10, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',\n",
      "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=False), classify__C=10, reduce_dim=PCA(copy=True, iterated_power=7, n_components=32, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), reduce_dim__n_components=32, score=0.2908857109457195, total= 6.4min\n",
      "[CV] classify=SVC(C=10, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',\n",
      "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=False), classify__C=10, reduce_dim=PCA(copy=True, iterated_power=7, n_components=32, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), reduce_dim__n_components=32 \n",
      "[CV]  classify=SVC(C=10, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',\n",
      "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=False), classify__C=10, reduce_dim=PCA(copy=True, iterated_power=7, n_components=32, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), reduce_dim__n_components=32, score=0.2926392081985738, total= 6.3min\n",
      "[CV] classify=SVC(C=10, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',\n",
      "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=False), classify__C=10, reduce_dim=PCA(copy=True, iterated_power=7, n_components=32, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), reduce_dim__n_components=64 \n",
      "[CV]  classify=SVC(C=10, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',\n",
      "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=False), classify__C=10, reduce_dim=PCA(copy=True, iterated_power=7, n_components=32, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), reduce_dim__n_components=64, score=0.261626548258939, total= 9.7min\n",
      "[CV] classify=SVC(C=10, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',\n",
      "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=False), classify__C=10, reduce_dim=PCA(copy=True, iterated_power=7, n_components=64, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), reduce_dim__n_components=64 \n",
      "[CV]  classify=SVC(C=10, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',\n",
      "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=False), classify__C=10, reduce_dim=PCA(copy=True, iterated_power=7, n_components=64, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), reduce_dim__n_components=64, score=0.2585044616763434, total= 9.9min\n",
      "[CV] classify=SVC(C=10, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',\n",
      "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=False), classify__C=10, reduce_dim=PCA(copy=True, iterated_power=7, n_components=64, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), reduce_dim__n_components=64 \n",
      "[CV]  classify=SVC(C=10, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',\n",
      "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=False), classify__C=10, reduce_dim=PCA(copy=True, iterated_power=7, n_components=64, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), reduce_dim__n_components=64, score=0.2603358921404356, total= 9.9min\n",
      "[CV] classify=SVC(C=10, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',\n",
      "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=False), classify__C=10, reduce_dim=PCA(copy=True, iterated_power=7, n_components=64, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), reduce_dim__n_components=128 \n",
      "[CV]  classify=SVC(C=10, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',\n",
      "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=False), classify__C=10, reduce_dim=PCA(copy=True, iterated_power=7, n_components=64, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), reduce_dim__n_components=128, score=0.34973124561813507, total=17.3min\n",
      "[CV] classify=SVC(C=10, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',\n",
      "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=False), classify__C=10, reduce_dim=PCA(copy=True, iterated_power=7, n_components=128, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), reduce_dim__n_components=128 \n",
      "[CV]  classify=SVC(C=10, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',\n",
      "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=False), classify__C=10, reduce_dim=PCA(copy=True, iterated_power=7, n_components=128, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), reduce_dim__n_components=128, score=0.34664692358648636, total=17.4min\n",
      "[CV] classify=SVC(C=10, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',\n",
      "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=False), classify__C=10, reduce_dim=PCA(copy=True, iterated_power=7, n_components=128, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), reduce_dim__n_components=128 \n",
      "[CV]  classify=SVC(C=10, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',\n",
      "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=False), classify__C=10, reduce_dim=PCA(copy=True, iterated_power=7, n_components=128, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), reduce_dim__n_components=128, score=0.3482055878112458, total=17.5min\n",
      "[CV] classify=SVC(C=10, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',\n",
      "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=False), classify__C=100, reduce_dim=PCA(copy=True, iterated_power=7, n_components=128, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), reduce_dim__n_components=32 \n",
      "[CV]  classify=SVC(C=10, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',\n",
      "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=False), classify__C=100, reduce_dim=PCA(copy=True, iterated_power=7, n_components=128, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), reduce_dim__n_components=32, score=0.29333177533691673, total= 6.4min\n",
      "[CV] classify=SVC(C=100, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',\n",
      "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=False), classify__C=100, reduce_dim=PCA(copy=True, iterated_power=7, n_components=32, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), reduce_dim__n_components=32 \n",
      "[CV]  classify=SVC(C=100, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',\n",
      "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=False), classify__C=100, reduce_dim=PCA(copy=True, iterated_power=7, n_components=32, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), reduce_dim__n_components=32, score=0.29084674434010055, total= 6.4min\n",
      "[CV] classify=SVC(C=100, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',\n",
      "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=False), classify__C=100, reduce_dim=PCA(copy=True, iterated_power=7, n_components=32, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), reduce_dim__n_components=32 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  classify=SVC(C=100, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',\n",
      "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=False), classify__C=100, reduce_dim=PCA(copy=True, iterated_power=7, n_components=32, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), reduce_dim__n_components=32, score=0.2926392081985738, total= 6.3min\n",
      "[CV] classify=SVC(C=100, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',\n",
      "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=False), classify__C=100, reduce_dim=PCA(copy=True, iterated_power=7, n_components=32, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), reduce_dim__n_components=64 \n",
      "[CV]  classify=SVC(C=100, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',\n",
      "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=False), classify__C=100, reduce_dim=PCA(copy=True, iterated_power=7, n_components=32, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), reduce_dim__n_components=64, score=0.261626548258939, total= 9.7min\n",
      "[CV] classify=SVC(C=100, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',\n",
      "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=False), classify__C=100, reduce_dim=PCA(copy=True, iterated_power=7, n_components=64, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), reduce_dim__n_components=64 \n",
      "[CV]  classify=SVC(C=100, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',\n",
      "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=False), classify__C=100, reduce_dim=PCA(copy=True, iterated_power=7, n_components=64, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), reduce_dim__n_components=64, score=0.2585044616763434, total= 9.7min\n",
      "[CV] classify=SVC(C=100, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',\n",
      "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=False), classify__C=100, reduce_dim=PCA(copy=True, iterated_power=7, n_components=64, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), reduce_dim__n_components=64 \n",
      "[CV]  classify=SVC(C=100, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',\n",
      "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=False), classify__C=100, reduce_dim=PCA(copy=True, iterated_power=7, n_components=64, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), reduce_dim__n_components=64, score=0.2603358921404356, total= 9.7min\n",
      "[CV] classify=SVC(C=100, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',\n",
      "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=False), classify__C=100, reduce_dim=PCA(copy=True, iterated_power=7, n_components=64, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), reduce_dim__n_components=128 \n",
      "[CV]  classify=SVC(C=100, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',\n",
      "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=False), classify__C=100, reduce_dim=PCA(copy=True, iterated_power=7, n_components=64, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), reduce_dim__n_components=128, score=0.34973124561813507, total=17.4min\n",
      "[CV] classify=SVC(C=100, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',\n",
      "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=False), classify__C=100, reduce_dim=PCA(copy=True, iterated_power=7, n_components=128, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), reduce_dim__n_components=128 \n",
      "[CV]  classify=SVC(C=100, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',\n",
      "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=False), classify__C=100, reduce_dim=PCA(copy=True, iterated_power=7, n_components=128, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), reduce_dim__n_components=128, score=0.34664692358648636, total=17.4min\n",
      "[CV] classify=SVC(C=100, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',\n",
      "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=False), classify__C=100, reduce_dim=PCA(copy=True, iterated_power=7, n_components=128, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), reduce_dim__n_components=128 \n",
      "[CV]  classify=SVC(C=100, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',\n",
      "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=False), classify__C=100, reduce_dim=PCA(copy=True, iterated_power=7, n_components=128, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), reduce_dim__n_components=128, score=0.3482055878112458, total=17.5min\n",
      "[CV] classify=SVC(C=100, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',\n",
      "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=False), classify__C=1000, reduce_dim=PCA(copy=True, iterated_power=7, n_components=128, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), reduce_dim__n_components=32 \n",
      "[CV]  classify=SVC(C=100, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',\n",
      "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=False), classify__C=1000, reduce_dim=PCA(copy=True, iterated_power=7, n_components=128, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), reduce_dim__n_components=32, score=0.2934486250681623, total= 6.4min\n",
      "[CV] classify=SVC(C=1000, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',\n",
      "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=False), classify__C=1000, reduce_dim=PCA(copy=True, iterated_power=7, n_components=32, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), reduce_dim__n_components=32 \n",
      "[CV]  classify=SVC(C=1000, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',\n",
      "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=False), classify__C=1000, reduce_dim=PCA(copy=True, iterated_power=7, n_components=32, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), reduce_dim__n_components=32, score=0.2908077777344816, total= 6.3min\n",
      "[CV] classify=SVC(C=1000, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',\n",
      "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=False), classify__C=1000, reduce_dim=PCA(copy=True, iterated_power=7, n_components=32, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), reduce_dim__n_components=32 \n",
      "[CV]  classify=SVC(C=1000, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',\n",
      "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=False), classify__C=1000, reduce_dim=PCA(copy=True, iterated_power=7, n_components=32, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), reduce_dim__n_components=32, score=0.2926781748041928, total= 6.3min\n",
      "[CV] classify=SVC(C=1000, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',\n",
      "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=False), classify__C=1000, reduce_dim=PCA(copy=True, iterated_power=7, n_components=32, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), reduce_dim__n_components=64 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  classify=SVC(C=1000, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',\n",
      "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=False), classify__C=1000, reduce_dim=PCA(copy=True, iterated_power=7, n_components=32, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), reduce_dim__n_components=64, score=0.261626548258939, total= 9.7min\n",
      "[CV] classify=SVC(C=1000, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',\n",
      "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=False), classify__C=1000, reduce_dim=PCA(copy=True, iterated_power=7, n_components=64, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), reduce_dim__n_components=64 \n",
      "[CV]  classify=SVC(C=1000, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',\n",
      "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=False), classify__C=1000, reduce_dim=PCA(copy=True, iterated_power=7, n_components=64, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), reduce_dim__n_components=64, score=0.2585044616763434, total= 9.7min\n",
      "[CV] classify=SVC(C=1000, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',\n",
      "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=False), classify__C=1000, reduce_dim=PCA(copy=True, iterated_power=7, n_components=64, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), reduce_dim__n_components=64 \n",
      "[CV]  classify=SVC(C=1000, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',\n",
      "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=False), classify__C=1000, reduce_dim=PCA(copy=True, iterated_power=7, n_components=64, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), reduce_dim__n_components=64, score=0.2603358921404356, total= 9.8min\n",
      "[CV] classify=SVC(C=1000, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',\n",
      "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=False), classify__C=1000, reduce_dim=PCA(copy=True, iterated_power=7, n_components=64, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), reduce_dim__n_components=128 \n",
      "[CV]  classify=SVC(C=1000, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',\n",
      "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=False), classify__C=1000, reduce_dim=PCA(copy=True, iterated_power=7, n_components=64, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), reduce_dim__n_components=128, score=0.34973124561813507, total=17.3min\n",
      "[CV] classify=SVC(C=1000, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',\n",
      "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=False), classify__C=1000, reduce_dim=PCA(copy=True, iterated_power=7, n_components=128, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), reduce_dim__n_components=128 \n",
      "[CV]  classify=SVC(C=1000, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',\n",
      "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=False), classify__C=1000, reduce_dim=PCA(copy=True, iterated_power=7, n_components=128, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), reduce_dim__n_components=128, score=0.34664692358648636, total=17.4min\n",
      "[CV] classify=SVC(C=1000, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',\n",
      "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=False), classify__C=1000, reduce_dim=PCA(copy=True, iterated_power=7, n_components=128, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), reduce_dim__n_components=128 \n",
      "[CV]  classify=SVC(C=1000, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',\n",
      "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=False), classify__C=1000, reduce_dim=PCA(copy=True, iterated_power=7, n_components=128, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), reduce_dim__n_components=128, score=0.3482055878112458, total=17.5min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  45 out of  45 | elapsed: 577.4min finished\n"
     ]
    }
   ],
   "source": [
    "grid_real_imag = gamut_classification_pca(X_real_imag, Y.ravel(), use_svm=False, n_estimators=[100], n_features=[32, 64, 128])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(memory=None,\n",
      "     steps=[('reduce_dim', PCA(copy=True, iterated_power=7, n_components=128, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False)), ('classify', SVC(C=1, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',\n",
      "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=False))])\n",
      "0.348194805195\n"
     ]
    }
   ],
   "source": [
    "print(grid_real_imag.best_estimator_)\n",
    "print(grid_real_imag.best_score_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'grid_real_imag' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-6d9a199a1478>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mclf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgrid_real_imag\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_estimator_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mtrue_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpred_y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_real_imag\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# Compute confusion matrix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mcnf_matrix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconfusion_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrue_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpred_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_printoptions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprecision\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'grid_real_imag' is not defined"
     ]
    }
   ],
   "source": [
    "clf = grid_real_imag.best_estimator_\n",
    "true_y, pred_y = Y.ravel(), clf.predict(X_real_imag).ravel()\n",
    "# Compute confusion matrix\n",
    "cnf_matrix = confusion_matrix(true_y, pred_y)\n",
    "np.set_printoptions(precision=2)\n",
    "\n",
    "# Plot non-normalized confusion matrix\n",
    "plt.figure(figsize=(10, 20))\n",
    "plot_confusion_matrix(cnf_matrix, classes=labels,\n",
    "                      title='Confusion matrix, without normalization')\n",
    "plt.show()\n",
    "\n",
    "# Plot normalized confusion matrix\n",
    "plt.figure(figsize=(10, 20))\n",
    "plot_confusion_matrix(cnf_matrix, classes=labels, normalize=True,\n",
    "                      title='Normalized confusion matrix')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7806883116883117\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for *: 'NoneType' and 'int'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-61-c18183ab7494>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdiag\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcnf_matrix\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m77000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: unsupported operand type(s) for *: 'NoneType' and 'int'"
     ]
    }
   ],
   "source": [
    "a = np.diag(cnf_matrix)\n",
    "s = sum(a)\n",
    "print(float(s)/77000)*100"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
